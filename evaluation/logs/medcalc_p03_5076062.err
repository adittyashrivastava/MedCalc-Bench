Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.61s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:06,  3.48s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.76s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/25 [00:00<?, ?it/s]/home/hrangara/miniconda3/envs/medCalcEnv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/hrangara/miniconda3/envs/medCalcEnv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  4%|▍         | 1/25 [00:05<02:09,  5.40s/it]  8%|▊         | 2/25 [00:10<01:54,  5.00s/it] 12%|█▏        | 3/25 [00:16<02:01,  5.52s/it] 16%|█▌        | 4/25 [00:21<01:52,  5.34s/it] 20%|██        | 5/25 [00:26<01:44,  5.21s/it] 24%|██▍       | 6/25 [00:31<01:41,  5.34s/it] 28%|██▊       | 7/25 [00:36<01:32,  5.13s/it] 32%|███▏      | 8/25 [00:41<01:26,  5.06s/it] 36%|███▌      | 9/25 [00:46<01:19,  4.96s/it] 40%|████      | 10/25 [00:50<01:12,  4.83s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
 44%|████▍     | 11/25 [00:56<01:09,  4.99s/it] 48%|████▊     | 12/25 [01:00<01:02,  4.84s/it] 52%|█████▏    | 13/25 [01:03<00:52,  4.38s/it] 56%|█████▌    | 14/25 [01:09<00:51,  4.68s/it] 60%|██████    | 15/25 [01:14<00:48,  4.84s/it] 64%|██████▍   | 16/25 [01:20<00:46,  5.14s/it] 68%|██████▊   | 17/25 [01:25<00:40,  5.09s/it] 72%|███████▏  | 18/25 [01:30<00:35,  5.04s/it] 76%|███████▌  | 19/25 [01:35<00:30,  5.01s/it] 80%|████████  | 20/25 [01:38<00:22,  4.59s/it] 84%|████████▍ | 21/25 [01:42<00:17,  4.25s/it] 88%|████████▊ | 22/25 [01:46<00:12,  4.17s/it] 92%|█████████▏| 23/25 [01:51<00:08,  4.40s/it] 96%|█████████▌| 24/25 [01:56<00:04,  4.60s/it]100%|██████████| 25/25 [02:01<00:00,  4.86s/it]100%|██████████| 25/25 [02:01<00:00,  4.87s/it]
