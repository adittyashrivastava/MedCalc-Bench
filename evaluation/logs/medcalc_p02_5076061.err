Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.37s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.10it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/25 [00:00<?, ?it/s]/home/hrangara/miniconda3/envs/medCalcEnv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/hrangara/miniconda3/envs/medCalcEnv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  4%|▍         | 1/25 [00:07<03:04,  7.67s/it]  8%|▊         | 2/25 [00:14<02:42,  7.07s/it] 12%|█▏        | 3/25 [00:19<02:14,  6.11s/it] 16%|█▌        | 4/25 [00:25<02:08,  6.11s/it] 20%|██        | 5/25 [00:31<02:05,  6.27s/it] 24%|██▍       | 6/25 [00:37<01:53,  5.96s/it] 28%|██▊       | 7/25 [00:44<01:52,  6.28s/it] 32%|███▏      | 8/25 [00:48<01:34,  5.54s/it] 36%|███▌      | 9/25 [00:53<01:26,  5.41s/it] 40%|████      | 10/25 [00:57<01:15,  5.04s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
 44%|████▍     | 11/25 [01:00<01:03,  4.55s/it] 48%|████▊     | 12/25 [01:05<00:57,  4.45s/it] 52%|█████▏    | 13/25 [01:09<00:53,  4.42s/it] 56%|█████▌    | 14/25 [01:12<00:43,  3.92s/it] 60%|██████    | 15/25 [01:16<00:38,  3.87s/it] 64%|██████▍   | 16/25 [01:19<00:34,  3.88s/it] 68%|██████▊   | 17/25 [01:23<00:30,  3.81s/it] 72%|███████▏  | 18/25 [01:27<00:25,  3.71s/it] 76%|███████▌  | 19/25 [01:30<00:21,  3.63s/it] 80%|████████  | 20/25 [01:33<00:17,  3.52s/it] 84%|████████▍ | 21/25 [01:37<00:14,  3.71s/it] 88%|████████▊ | 22/25 [01:41<00:10,  3.63s/it] 92%|█████████▏| 23/25 [01:44<00:07,  3.58s/it] 96%|█████████▌| 24/25 [01:49<00:03,  3.82s/it]100%|██████████| 25/25 [01:53<00:00,  3.81s/it]100%|██████████| 25/25 [01:53<00:00,  4.52s/it]
